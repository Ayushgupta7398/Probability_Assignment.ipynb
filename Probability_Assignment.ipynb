{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmh-jJ8-yKsW"
      },
      "outputs": [],
      "source": [
        "# Q1  a. Tossing a coin 10,000 times and calculating the experimental probability of heads and tails.\n",
        "\n",
        "import random\n",
        "\n",
        "# --- 1a. Tossing a coin 10,000 times ---\n",
        "print(\"--- 1a. Tossing a coin 10,000 times ---\")\n",
        "num_tosses = 10000\n",
        "heads = 0\n",
        "tails = 0\n",
        "\n",
        "for _ in range(num_tosses):\n",
        "    if random.random() < 0.5: # Assuming 0.5 for heads (e.g., <0.5) and >=0.5 for tails\n",
        "        heads += 1\n",
        "    else:\n",
        "        tails += 1\n",
        "\n",
        "experimental_prob_heads = heads / num_tosses\n",
        "experimental_prob_tails = tails / num_tosses\n",
        "\n",
        "print(f\"Total tosses: {num_tosses}\")\n",
        "print(f\"Heads: {heads}\")\n",
        "print(f\"Tails: {tails}\")\n",
        "print(f\"Experimental probability of Heads: {experimental_prob_heads:.4f}\")\n",
        "print(f\"Experimental probability of Tails: {experimental_prob_tails:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explanation for Q1 a:\n",
        "\n",
        "\n",
        "\n",
        " ## What the code does:\n",
        "\n",
        "   It pretends to flip a coin 10,000 times.\n",
        "\n",
        "   Each time, it decides if it's \"Heads\" or \"Tails\" randomly (like a real coin).\n",
        "\n",
        "   It counts how many Heads and how many Tails it got.\n",
        "\n",
        "   Finally, it tells you what percentage of the flips were Heads and what percentage were Tails.\n",
        "\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " If you flip a coin only a few times, you might get more Heads than Tails, or vice versa. But if you flip it a lot of times (like 10,000),\n",
        " you'll see that the number of Heads and Tails gets very close to 50% each. This shows how probability works over many tries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ip5N736y5Ef"
      },
      "outputs": [],
      "source": [
        " # Q1 b. Rolling two dice and computing the probability of getting a sum of 7.\n",
        "\n",
        "import random\n",
        "\n",
        "# --- 1b. Rolling two dice and computing the probability of getting a sum of 7 ---\n",
        "print(\"\\n--- 1b. Rolling two dice and computing the probability of getting a sum of 7 ---\")\n",
        "num_rolls = 100000 # Increased rolls for better approximation\n",
        "sum_seven_count = 0\n",
        "\n",
        "for _ in range(num_rolls):\n",
        "    die1 = random.randint(1, 6)\n",
        "    die2 = random.randint(1, 6)\n",
        "    if die1 + die2 == 7:\n",
        "        sum_seven_count += 1\n",
        "\n",
        "experimental_prob_sum_seven = sum_seven_count / num_rolls\n",
        "\n",
        "print(f\"Total rolls: {num_rolls}\")\n",
        "print(f\"Times sum was 7: {sum_seven_count}\")\n",
        "print(f\"Experimental probability of getting a sum of 7: {experimental_prob_sum_seven:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1b. Rolling two dice and computing the probability of getting a sum of 7\n",
        "\n",
        " It pretends to roll two dice (each with numbers 1 to 6) a huge number of times (100,000 times to be accurate!).\n",
        "\n",
        " For each roll, it adds the numbers on the two dice together.\n",
        "\n",
        " It counts how many times the total sum was exactly 7.\n",
        "\n",
        " Then, it tells you what percentage of the rolls resulted in a sum of 7.\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " There are many ways two dice can add up, but 7 is the most common sum (like 1+6, 2+5, 3+4, etc.). By doing this experiment many times,\n",
        "  the computer shows you that 7 comes up quite often, and the percentage it calculates will be very close to what you'd expect mathematically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqrhTL9gzbky"
      },
      "outputs": [],
      "source": [
        "#  Q2  Write a function to estimate the probability of getting at least one \"6\" in 10 rolls of a fair die.\n",
        "import random\n",
        "\n",
        "# --- Problem 2: Estimate the probability of getting at least one \"6\" in 10 rolls ---\n",
        "print(\"\\n--- Problem 2: Estimate the probability of getting at least one '6' in 10 rolls ---\")\n",
        "\n",
        "def estimate_prob_at_least_one_six(num_simulations=100000):\n",
        "    \"\"\"\n",
        "    Estimates the probability of getting at least one '6' in 10 rolls of a fair die.\n",
        "    \"\"\"\n",
        "    successful_trials = 0\n",
        "    for _ in range(num_simulations):\n",
        "        has_six = False\n",
        "        for _ in range(10): # 10 rolls\n",
        "            roll = random.randint(1, 6)\n",
        "            if roll == 6:\n",
        "                has_six = True\n",
        "                break # No need to roll further if a 6 is found\n",
        "        if has_six:\n",
        "            successful_trials += 1\n",
        "\n",
        "    probability = successful_trials / num_simulations\n",
        "    return probability\n",
        "\n",
        "num_simulations_for_prob_six = 100000\n",
        "estimated_prob = estimate_prob_at_least_one_six(num_simulations_for_prob_six)\n",
        "print(f\"Number of simulations: {num_simulations_for_prob_six}\")\n",
        "print(f\"Estimated probability of getting at least one '6' in 10 rolls: {estimated_prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q2 Probability of at least one \"6\" in 10 rolls\n",
        "\n",
        " This problem asks us to find out how likely it is to get at least one \"6\" if you roll a single die 10 times.\n",
        "\n",
        "## What the code does:\n",
        "\n",
        "  It runs a big experiment (100,000 times).\n",
        "\n",
        "  In each experiment, it rolls a die 10 times.\n",
        "\n",
        "  It checks if any of those 10 rolls resulted in a \"6\". If even one \"6\" appears, that experiment is counted as a \"success.\"\n",
        "\n",
        "  After all 100,000 experiments, it tells you what percentage of them were \"successful\" (meaning they had at least one \"6\").\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " It's easier to think about not getting a 6. If you roll a die 10 times, it's pretty hard to never get a 6. So, the chance of getting at least one 6 is quite high.\n",
        " The simulation helps us see this high probability in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d23C08k1HoU"
      },
      "outputs": [],
      "source": [
        "#  Q3--- Problem 3: Conditional Probability and Bayes' Theorem ---\n",
        "import random\n",
        "\n",
        "print(\"\\n--- Problem 3: Conditional Probability and Bayes' Theorem ---\")\n",
        "\n",
        "# Define the bag contents\n",
        "bag = ['red'] * 5 + ['green'] * 7 + ['blue'] * 8\n",
        "num_trials = 1000\n",
        "\n",
        "# Track outcomes\n",
        "draw_sequence = []\n",
        "for _ in range(num_trials):\n",
        "    draw_sequence.append(random.choice(bag))\n",
        "\n",
        "# Compute probabilities directly from the data\n",
        "red_count = draw_sequence.count('red')\n",
        "green_count = draw_sequence.count('green')\n",
        "blue_count = draw_sequence.count('blue')\n",
        "\n",
        "prob_red_empirical = red_count / num_trials\n",
        "prob_blue_empirical = blue_count / num_trials\n",
        "prob_green_empirical = green_count / num_trials\n",
        "\n",
        "print(f\"Empirical P(Red): {prob_red_empirical:.4f}\")\n",
        "print(f\"Empirical P(Green): {prob_green_empirical:.4f}\")\n",
        "print(f\"Empirical P(Blue): {prob_blue_empirical:.4f}\")\n",
        "\n",
        "# a. The probability of drawing a red ball given that the previous ball was blue.\n",
        "# Due to replacement, draws are independent. So, P(Red | Previous Blue) = P(Red).\n",
        "# We can confirm this by counting actual occurrences.\n",
        "\n",
        "blue_then_red_count = 0\n",
        "previous_draw = None\n",
        "for current_draw in draw_sequence:\n",
        "    if previous_draw == 'blue' and current_draw == 'red':\n",
        "        blue_then_red_count += 1\n",
        "    previous_draw = current_draw\n",
        "\n",
        "# Total instances where the previous ball was blue\n",
        "previous_blue_count = 0\n",
        "for i in range(1, num_trials):\n",
        "    if draw_sequence[i-1] == 'blue':\n",
        "        previous_blue_count += 1\n",
        "\n",
        "# Handle division by zero if previous_blue_count is 0 (unlikely with 1000 trials)\n",
        "if previous_blue_count > 0:\n",
        "    prob_red_given_previous_blue_empirical = blue_then_red_count / previous_blue_count\n",
        "else:\n",
        "    prob_red_given_previous_blue_empirical = 0\n",
        "print(f\"\\nEmpirical P(Red | Previous is Blue): {prob_red_given_previous_blue_empirical:.4f}\")\n",
        "\n",
        "# b. Verify Bayes' theorem with the simulation results.\n",
        "# Bayes' Theorem: P(A|B) = P(B|A) * P(A) / P(B)\n",
        "# Let A = 'Red', B = 'Previous Blue'\n",
        "# P(Red | Previous Blue) should be approximately P(Red) in an independent process.\n",
        "\n",
        "# P(Previous Blue | Red) is the probability that the previous ball was blue given the current one is red.\n",
        "# In an independent process, this is just P(Previous Blue).\n",
        "# We need to calculate P(Previous Blue | Red) empirically:\n",
        "# Count cases where current is Red AND previous is Blue (already calculated as blue_then_red_count)\n",
        "# Count cases where current is Red (red_count)\n",
        "if red_count > 0:\n",
        "    prob_previous_blue_given_red_empirical = blue_then_red_count / red_count\n",
        "else:\n",
        "    prob_previous_blue_given_red_empirical = 0\n",
        "\n",
        "print(f\"Empirical P(Previous is Blue | Current is Red): {prob_previous_blue_given_red_empirical:.4f}\")\n",
        "\n",
        "# Apply Bayes' Theorem using empirical values:\n",
        "# Estimated P(Red | Previous Blue) = P(Previous Blue | Red) * P(Red) / P(Previous Blue)\n",
        "if prob_blue_empirical > 0:\n",
        "    bayes_estimate_red_given_blue = (prob_previous_blue_given_red_empirical * prob_red_empirical) / prob_blue_empirical\n",
        "else:\n",
        "    bayes_estimate_red_given_blue = 0\n",
        "\n",
        "print(f\"Bayes' Theorem estimate of P(Red | Previous is Blue): {bayes_estimate_red_given_blue:.4f}\")\n",
        "print(f\"Expected P(Red) (theoretical): {5/20:.4f}\")\n",
        "\n",
        "# Verification: The empirical P(Red | Previous is Blue) should be close to the empirical P(Red),\n",
        "# and the Bayes' Theorem estimate should also be close to P(Red).\n",
        "# This demonstrates independence where P(A|B) = P(A).\n",
        "print(f\"\\nVerification: The empirical P(Red | Previous is Blue) ({prob_red_given_previous_blue_empirical:.4f}) \"\n",
        "      f\"is close to the empirical P(Red) ({prob_red_empirical:.4f}), \"\n",
        "      f\"confirming independence and consistency with Bayes' theorem.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Q3 Conditional Probability and Bayes' Theorem\n",
        "\n",
        " This part is about drawing colored balls from a bag and understanding how one draw relates to the next, even if we put the ball back.\n",
        "\n",
        " ### The setup: \n",
        "\n",
        "   You have a bag with 5 red, 7 green, and 8 blue balls. You pick one, note its color, and put it back. You do this 1000 times.\n",
        "\n",
        " ## What the code does:\n",
        "\n",
        "   It looks at all the times you drew a blue ball, and then checks what color you drew next.# It then calculates the percenta\n",
        "\n",
        "   It simulates picking a ball 1000 times, always putting it back.\n",
        "\n",
        "   It counts how many times each color (red, green, blue) was picked and shows you the percentage for each.\n",
        "\n",
        " ### Part a : \n",
        "   Probability of dge of times that \"next\" ball was red.\n",
        "\n",
        " ### Part b (Verify Bayes' Theorem): \n",
        "   This is a bit more mathy, but simply, the code calculates some other probabilities (like the chance of seeing a blue ball\n",
        "   if the next one is red) and then uses a special formula (Bayes' Theorem) to see if the numbers match up.\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " Because you put the ball back every time, each draw is completely separate from the last one. So, the chance of drawing a red ball is always the same (5 out of 20, or 25%),\n",
        " no matter what color you drew before. The code will show you that the \"probability of red given previous was blue\" is basically the same as just \"probability of red.\"\n",
        "\n",
        " This confirms that the draws are independent. Bayes' Theorem, when applied, will also confirm this independence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-IGG_7E1RAN"
      },
      "outputs": [],
      "source": [
        "# Q4 --- Problem 4: Random Variables and Discrete Probability ---\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Problem 4: Random Variables and Discrete Probability ---\")\n",
        "\n",
        "# Define values and their probabilities\n",
        "values = [1, 2, 3]\n",
        "probabilities = [0.25, 0.35, 0.40]\n",
        "sample_size = 1000\n",
        "\n",
        "# Generate the sample\n",
        "sample = np.random.choice(values, size=sample_size, p=probabilities)\n",
        "\n",
        "# Compute empirical mean, variance, and standard deviation\n",
        "empirical_mean = np.mean(sample)\n",
        "empirical_variance = np.var(sample)\n",
        "empirical_std_dev = np.std(sample)\n",
        "\n",
        "print(f\"Generated sample (first 10 elements): {sample[:10]}\")\n",
        "print(f\"Sample size: {sample_size}\")\n",
        "print(f\"Empirical Mean: {empirical_mean:.4f}\")\n",
        "print(f\"Empirical Variance: {empirical_variance:.4f}\")\n",
        "print(f\"Empirical Standard Deviation: {empirical_std_dev:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Q4 Random Variables and Discrete Probability\n",
        "\n",
        " This problem is about working with numbers that have specific chances of showing up, like if you had a special die that was weighted so some numbers came up more often.\n",
        "\n",
        "### The setup: We have a \"variable\" (let's call it X) that can only be 1, 2, or 3.\n",
        "\n",
        "    X has a 25% chance of being 1.\n",
        "\n",
        "    X has a 35% chance of being 2.\n",
        "\n",
        "    X has a 40% chance of being 3.\n",
        "\n",
        "## What the code does:\n",
        "\n",
        "    It creates a list of 1000 numbers based on these chances (so, about 250 will be 1s, 350 will be 2s, and 400 will be 3s).\n",
        "\n",
        "    It then calculates:\n",
        "\n",
        "   * Mean (Average): The average value of all 1000 numbers in the list.\n",
        "\n",
        "   * Variance: How spread out the numbers are from the average. A higher variance means the numbers are more scattered.\n",
        "\n",
        "   * Standard Deviation: Another way to measure spread, which is just the square root of the variance. It's easier to understand because it's in the same units as the numbers themselves.\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " This helps us understand the typical value and the spread of data when numbers don't have an equal chance of appearing.\n",
        " The numbers the code calculates (mean, variance, standard deviation) should be very close to what you'd calculate using math for this specific set of chances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUmOn-dm1dZf"
      },
      "outputs": [],
      "source": [
        "# Q5 --- Problem 5: Continuous Random Variables ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "print(\"\\n--- Problem 5: Continuous Random Variables ---\")\n",
        "\n",
        "# Parameters for exponential distribution\n",
        "mean_exp = 5\n",
        "scale_exp = mean_exp # For numpy, scale is the mean (1/lambda)\n",
        "num_samples_exp = 2000\n",
        "\n",
        "# Simulate random samples\n",
        "samples_exp = np.random.exponential(scale=scale_exp, size=num_samples_exp)\n",
        "\n",
        "# a. Visualize the distribution using a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(samples_exp, bins=50, density=True, alpha=0.6, color='skyblue', label='Simulated Samples (Histogram)')\n",
        "plt.title('Distribution of Exponential Samples with PDF Overlay')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "# b. Overlay with a Probability Density Function (PDF)\n",
        "# Generate x-values for the PDF curve\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(0, xmax, 100) # Start from 0 for exponential distribution\n",
        "\n",
        "# Calculate PDF values for exponential distribution\n",
        "pdf_values = stats.expon.pdf(x, scale=scale_exp)\n",
        "plt.plot(x, pdf_values, 'r-', lw=2, label='Theoretical PDF (Exponential)')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "print(\"Histogram and PDF overlay plotted successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Q5 Continuous Random Variables\n",
        "\n",
        "This part is about numbers that can be any value within a range, not just specific whole numbers. Think of things like how long you have to wait for a bus.\n",
        "\n",
        "### The setup:\n",
        "\n",
        "  We're looking at something that follows an \"exponential distribution\" with an average (mean) of 5. This kind of distribution often describes waiting times \n",
        "  you're more likely to wait a short time than a very long time.\n",
        "\n",
        "## What the code does:\n",
        "\n",
        "  It generates 2000 random numbers that follow this \"waiting time\" pattern.\n",
        "\n",
        " ### Part a (Histogram):\n",
        "\n",
        "   It draws a bar chart (histogram) showing how often different waiting times appeared in our 2000 samples. You'll see taller bars for\n",
        "   shorter waiting times and shorter bars for longer waiting times.\n",
        "\n",
        " ### Part b (PDF Overlay):\n",
        "\n",
        "   It then draws a smooth curve over the bar chart. This curve is the \"Probability Density Function\" (PDF), which is the mathematical shape\n",
        "   that an exponential distribution should have.\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " This helps us visualize continuous data. The histogram shows what we actually got from our simulation,\n",
        " and the smooth curve shows the ideal shape of this type of distribution. You'll see that your simulated data (the bars) closely matches the ideal shape (the curve),\n",
        " especially with 2000 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns8jF7Hx1k7j"
      },
      "outputs": [],
      "source": [
        "# Q6--- Problem 6: Central Limit Theorem ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "print(\"\\n--- Problem 6: Central Limit Theorem ---\")\n",
        "\n",
        "# a. Generate 10,000 random numbers from a uniform distribution.\n",
        "uniform_data_size = 10000\n",
        "uniform_samples = np.random.uniform(low=0, high=1, size=uniform_data_size)\n",
        "\n",
        "# b. Draw 1000 samples of size n = 30.\n",
        "num_samples_clt = 1000\n",
        "sample_size_n = 30\n",
        "sample_means = []\n",
        "\n",
        "for _ in range(num_samples_clt):\n",
        "    # Draw a sample of size n from the uniform distribution (with replacement)\n",
        "    sample = np.random.choice(uniform_samples, size=sample_size_n, replace=True)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "sample_means = np.array(sample_means)\n",
        "\n",
        "# c. Calculate and visualize the distribution of sample means.\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the original uniform distribution (as a histogram)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(uniform_samples, bins=30, density=True, alpha=0.7, color='lightcoral')\n",
        "plt.title('Original Uniform Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot the distribution of sample means (as a histogram)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(sample_means, bins=30, density=True, alpha=0.7, color='lightgreen')\n",
        "plt.title(f'Distribution of Sample Means (n={sample_size_n})')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Overlay a normal distribution on the sample means histogram for comparison\n",
        "mu_sample_means = np.mean(sample_means)\n",
        "sigma_sample_means = np.std(sample_means)\n",
        "xmin, xmax = plt.xlim()\n",
        "x_norm = np.linspace(xmin, xmax, 100)\n",
        "p = stats.norm.pdf(x_norm, mu_sample_means, sigma_sample_means)\n",
        "plt.plot(x_norm, p, 'r', linewidth=2, label='Normal Approximation')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Histograms for original uniform distribution and sample means distribution plotted successfully.\")\n",
        "print(f\"Mean of sample means: {mu_sample_means:.4f}\")\n",
        "print(f\"Standard deviation of sample means: {sigma_sample_means:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q6 Central Limit Theorem\n",
        "\n",
        "## What the code does:\n",
        "\n",
        "### Step a (Original Data):\n",
        "\n",
        "   It first creates 10,000 random numbers that are evenly spread out between 0 and 1 (this is a \"uniform distribution\" – imagine a flat line).\n",
        "\n",
        "### Step b\n",
        " (Take Samples and Average):\n",
        "\n",
        "  It then takes 1000 small groups (each group has 30 numbers) from that original 10,000. For each of these 1000 groups, it calculates the average.\n",
        "\n",
        "### Step c \n",
        "(Visualize the Averages):\n",
        "\n",
        "  It shows you a bar chart of the original 10,000 numbers (which will look pretty flat).\n",
        "\n",
        "  Then, right next to it, it shows you a bar chart of the 1000 averages you just calculated.\n",
        "\n",
        "  You'll see that this second bar chart (of the averages) looks much more like a bell curve, even though the original data was flat! It even draws a\n",
        "  perfect bell curve over it to show how close it is.\n",
        "\n",
        "# Why it's important:\n",
        "\n",
        " This theorem is super powerful because it means that even if we don't know much about our original data, if we take enough samples and average them,\n",
        "  those averages will behave predictably (like a normal bell curve). This is a cornerstone of many statistical tests and predictions in the real world."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
